{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNcp8aS3OgeNMeUniUVsSmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbtmddn41/deep_learning/blob/main/translater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3qTbnoJwvoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97a7450-57ee-4309-cab2-80610a56a741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/딥러닝/keras_creator/Lecture 11.\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
        "FOLDERNAME = '딥러닝/keras_creator/Lecture\\ 11.'\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "!pip install konlpy\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "hWRdad1xxABT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372daca6-a246-4eaf-93a0-2bf37b5139a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace('[', '')\n",
        "strip_chars = strip_chars.replace(']', '')\n",
        "okt = Okt()\n",
        "\n",
        "def target_standardization(input_string):\n",
        "    lower_case = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lower_case, f\"[{re.escape(strip_chars)}]\", '')\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_len = 35\n",
        "\n",
        "korean_vectorization = layers.TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_len)\n",
        "english_vectorization = layers.TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_len+1, standardize=target_standardization)\n",
        "\n",
        "import pickle\n",
        "with open('kor_vocab.pkl', 'rb') as f:\n",
        "    kor_vocab = pickle.load(f)\n",
        "    korean_vectorization.set_vocabulary(kor_vocab)\n",
        "\n",
        "with open('eng_vocab.pkl', 'rb') as f:\n",
        "    eng_vocab = pickle.load(f)\n",
        "    english_vectorization.set_vocabulary(eng_vocab)"
      ],
      "metadata": {
        "id": "oh5H7fcmxMiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=self.dropout_rate)\n",
        "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation='relu'), layers.Dense(embed_dim)])\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(query=inputs, value=inputs, attention_mask=mask)\n",
        "        x = inputs + self.dropout1(attention_output)\n",
        "        x = self.layernorm_1(x)\n",
        "        proj_output = self.dense_proj(x)\n",
        "        x = self.dropout2(proj_output) + x\n",
        "        output = self.layernorm_2(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"embed_dim\": self.embed_dim, \"dense_dim\": self.dense_dim, \"num_heads\": self.num_heads, 'dropout_rate': self.dropout_rate})\n",
        "        return config\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_len, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)#, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)\n",
        "        self.position_embeddings = layers.Embedding(input_dim=sequence_len, output_dim=output_dim)\n",
        "        self.sequence_len = sequence_len\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"sequence_len\": self.sequence_len, \"input_dim\": self.input_dim, \"output_dim\": self.output_dim})\n",
        "        return config\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, num_blocks, sequence_len, vocab_size, embed_dim, dense_dim, num_heads, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_blocks = num_blocks\n",
        "        self.sequence_len = sequence_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(sequence_len, vocab_size, embed_dim)\n",
        "        block_layers = []\n",
        "        for i in range(num_blocks):\n",
        "            block_layers.append(TransformerEncoderBlock(embed_dim, dense_dim, num_heads, dropout_rate))\n",
        "        self.block_layers = keras.Sequential(block_layers)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        pos_inputs = self.pos_embedding(inputs)\n",
        "        encoded = self.block_layers(pos_inputs)\n",
        "        return encoded\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'num_blocks': self.num_blocks, 'sequence_len': self.sequence_len,\n",
        "            'vocab_size': self.vocab_size, 'embed_dim': self.embed_dim,\n",
        "            'dense_dim': self.dense_dim, 'num_heads': self.num_heads,\n",
        "            'dropout_rate': self.dropout_rate\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class TransformerDecoderBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)\n",
        "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)\n",
        "        self.dense_proj = keras.Sequential([\n",
        "            layers.Dense(dense_dim, activation='relu'),\n",
        "            layers.Dense(embed_dim)\n",
        "        ])\n",
        "\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "        self.dropout3 = layers.Dropout(dropout_rate)\n",
        "\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"embed_dim\": self.embed_dim, \"dense_dim\": self.dense_dim, \"num_heads\": self.num_heads, 'dropout_rate': self.dropout_rate})\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_len = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_len)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_len)\n",
        "        mask = tf.cast(i >= j, dtype='int32')\n",
        "        mask = tf.reshape(mask, (1, sequence_len, sequence_len))\n",
        "        mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype='int32')\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        attention_output_1 = self.attention_1(query=inputs, key=inputs, value=inputs, attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(self.dropout1(attention_output_1)+inputs)\n",
        "        attention_output_2 = self.attention_2(query=attention_output_1, key=encoder_outputs, value=encoder_outputs, attention_mask=padding_mask)\n",
        "        attention_output_2 = self.layernorm_2(self.dropout2(attention_output_2) + attention_output_1)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        outputs = self.layernorm_3(attention_output_2 + self.dropout3(proj_output))\n",
        "        return outputs\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, num_blocks, sequence_len, vocab_size, embed_dim, dense_dim, num_heads, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_blocks = num_blocks\n",
        "        self.sequence_len = sequence_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(sequence_len, vocab_size, embed_dim)\n",
        "        self.block_layers = []\n",
        "        for i in range(num_blocks):\n",
        "            self.block_layers.append(TransformerDecoderBlock(embed_dim, dense_dim, num_heads, dropout_rate))\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.dense = layers.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, encoder_outputs):\n",
        "        x = self.pos_embedding(inputs)\n",
        "        for decoder_block in self.block_layers:\n",
        "            x = decoder_block(x, encoder_outputs)\n",
        "        x = self.dropout(x)\n",
        "        outputs = self.dense(x)\n",
        "        return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'num_blocks': self.num_blocks, 'sequence_len': self.sequence_len,\n",
        "            'vocab_size': self.vocab_size, 'embed_dim': self.embed_dim,\n",
        "            'dense_dim': self.dense_dim, 'num_heads': self.num_heads,\n",
        "            'dropout_rate': self.dropout_rate\n",
        "            })\n",
        "        return config"
      ],
      "metadata": {
        "id": "Hk9sAjOYxSOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = keras.models.load_model('seq2seq_transformer.keras', custom_objects={'TransformerEncoderBlock': TransformerEncoderBlock, 'PositionalEmbedding': PositionalEmbedding,\n",
        "                                    'TransformerEncoder': TransformerEncoder, 'TransformerDecoderBlock': TransformerDecoderBlock, 'TransformerDecoder': TransformerDecoder})\n",
        "encoder = transformer.layers[2]\n",
        "decoder = transformer.layers[3]\n",
        "print(encoder.name, decoder.name)"
      ],
      "metadata": {
        "id": "-s6F1vf_xeiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5c6ff3-dec3-487b-e0c9-a76d15847f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer_encoder transformer_decoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_len = 35"
      ],
      "metadata": {
        "id": "wcF39LAHy00K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "eng_vocab = english_vectorization.get_vocabulary()\n",
        "eng_index_lookup = np.pad(np.array(eng_vocab), pad_width=(0,vocab_size), mode='constant', constant_values='[UNK]')[:vocab_size]\n",
        "max_decoded_sentence_len = sequence_len\n",
        "def decode_sequence(input_vectors):\n",
        "    batch_size = input_vectors.shape[0]\n",
        "    encoded_input_sentence = encoder.predict(input_vectors)\n",
        "    decoded_sentence = np.repeat(np.array('[start]'), batch_size).reshape(-1, 1)\n",
        "    blank = np.repeat(np.array(' '), batch_size).reshape(-1, 1)\n",
        "    print(blank.shape)\n",
        "    tokenized_target_sentence = english_vectorization(decoded_sentence)[:, :-1]\n",
        "    tokenized_target_sentence = tf.Variable(initial_value=tokenized_target_sentence)\n",
        "\n",
        "    for i in range(max_decoded_sentence_len):\n",
        "        next_token_predict = decoder.predict([tokenized_target_sentence, encoded_input_sentence])\n",
        "        # sampled_token_index = tf.random.categorical(next_token_predict[:, i], 1)\n",
        "        sampled_token_index = np.argmax(next_token_predict[:, i],axis=1).reshape(-1, 1)\n",
        "        sampled_token = eng_index_lookup[sampled_token_index]\n",
        "        if i < max_decoded_sentence_len-1:\n",
        "            tokenized_target_sentence[:, i+1, tf.newaxis].assign(sampled_token_index)\n",
        "        decoded_sentence = np.char.add(decoded_sentence, np.char.add(blank, sampled_token))\n",
        "        if sampled_token == '[end]':\n",
        "            break\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "KbYQE9GNxjC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이곳에 번역할 한글 문장을 입력."
      ],
      "metadata": {
        "id": "6_Ig9kOexjPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "korean_sentence = \"옷이 다 찢어져 있으니 좀 새로 사 입어라.\"\n",
        "\n",
        "preprocessed_korean_sentence = ' '.join(okt.morphs(korean_sentence))\n",
        "print(preprocessed_korean_sentence)\n",
        "korean_vector = korean_vectorization(preprocessed_korean_sentence)\n",
        "print(korean_vector)"
      ],
      "metadata": {
        "id": "1rnAyLIMxn1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8181c9-f56e-4d08-f868-3605d08299f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "옷 이 다 찢어져 있으니 좀 새로 사 입어라 .\n",
            "tf.Tensor(\n",
            "[1365    2   43    1 2803  519 1621  200    1    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0], shape=(35,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_sentence = decode_sequence(korean_vector[tf.newaxis, :])"
      ],
      "metadata": {
        "id": "M_Uo4Pgxy-9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f8cff8-dc38-4077-9c4b-523d5a876f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 78ms/step\n",
            "(1, 1)\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(re.sub(\"\\[start\\]|\\[end\\]\", \"\", translated_sentence[0][0]).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o798ybnAXeqC",
        "outputId": "10ec2201-14e8-49a8-bc99-47abc58605da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the clothes are all ripped so ill buy a new one\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whHV-23yZa0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R3BljixsYA30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}